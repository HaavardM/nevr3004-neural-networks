\section{Abstract}
The Hopfield network is an important model for understanding the mechanisms behind associative memory, and is an important basis for many state-of-the-art methods in artifical neural networks. In this paper we utilize numerical and analytical methods to show how the Hopfield network with a Hebbian learning rule always converges toward a local equilibrium. By borrowing the concept of energy from physics, we will build an intuitve understanding for how the Hopfield network may be used to model associative memory.  